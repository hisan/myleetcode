{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hisan/myleetcode/blob/master/Welcome_To_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Learning-OpenCV-4-Computer-Vision-with-Python-3"
      ],
      "metadata": {
        "id": "-tqBFBDkVbGg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chapter 2: Handling Files, Cameras, and GUIs"
      ],
      "metadata": {
        "id": "kxBZRKgcV_Q6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "a multidimensional array; it has columns and rows of pixels, and each pixel has a value, represented by a single 8-bit integer:\n",
        "    0 is black, 255 is white"
      ],
      "metadata": {
        "id": "InFB2hKPpMXB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "import cv2\n",
        "\n",
        "img = numpy.zeros((3, 3), dtype=numpy.uint8)\n",
        "print(img)\n",
        "print(\"----------------\\n\")\n",
        "img2 = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
        "print(img2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOOhXt95Vvwa",
        "outputId": "e9718dfb-b942-49e9-d653-92873dd52821"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]]\n",
            "----------------\n",
            "\n",
            "[[[0 0 0]\n",
            "  [0 0 0]\n",
            "  [0 0 0]]\n",
            "\n",
            " [[0 0 0]\n",
            "  [0 0 0]\n",
            "  [0 0 0]]\n",
            "\n",
            " [[0 0 0]\n",
            "  [0 0 0]\n",
            "  [0 0 0]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "如上示例,演示了一个3x3的 `Grayscale Image` 和 3x3x3的 `Color Image` in BGR(Blue, Green, Red) format.\n",
        "\n",
        "### `Grayscale Image` and `Color Image`:\n",
        "| **Grayscale**                        | **BGR (Color)**                     |\n",
        "|--------------------------------------|-------------------------------------|\n",
        "| Requires less memory (1 byte/pixel). | Requires more memory (3 bytes/pixel). |\n",
        "| Used for tasks where color is not important (e.g., edge detection, thresholding). | Required for tasks involving color analysis (e.g., object detection, color segmentation). |\n",
        "| Simpler to process and faster for computation. | More information for advanced processing. |\n",
        "| Not suitable for applications requiring color. | Suitable for color-dependent tasks. |\n",
        "\n",
        "pixels: 3x3 = 9 <==> Width x Height\n",
        "所以通常说的1920x1080分辨率,即 2073600 个pixels. 即像素点越多图像越清晰.\n",
        "\n",
        "而对于灰度图来说, 用一个byte来表示一个pixel. 而对于颜色图, 则是3个color channel表示一个pixel, 每个color channel用一个byte来表示.\n",
        "\n",
        "如上img2:\n",
        "~~~sh\n",
        "img2 = [\n",
        "    [[0, 0, 0], [0, 0, 0], [0, 0, 0]],  # Row 0\n",
        "    [[0, 0, 0], [0, 0, 0], [0, 0, 0]],  # Row 1\n",
        "    [[0, 0, 0], [0, 0, 0], [0, 0, 0]]   # Row 2\n",
        "]\n",
        "~~~\n",
        "row x column x channel:\n",
        "即三行,每行三列,每列一个Pixel,由三个color channel组成.\n",
        "\n",
        "img2[0][0] 表示一个pixel.\n",
        "img2[0][0][0]: Blue channel value for the pixel.\n",
        "img2[0][0][1]: Green channel value for the pixel.\n",
        "img2[0][0][2]: Red channel value for the pixel."
      ],
      "metadata": {
        "id": "08-2VG4zoXLk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "使用3x3x3的array来生成Color image的示例"
      ],
      "metadata": {
        "id": "ZYb8z1Rdnc11"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow  # Use this only for Google Colab\n",
        "\n",
        "# Create a 20x20x3 array representing the image\n",
        "img = np.zeros((20, 20, 3), dtype=np.uint8)\n",
        "\n",
        "# Fill the top-left (10x10) with red\n",
        "img[:10, :10] = [0, 0, 255]  # Red (BGR)\n",
        "\n",
        "# Fill the top-right (10x10) with green\n",
        "img[:10, 10:] = [0, 255, 0]  # Green (BGR)\n",
        "\n",
        "# Fill the bottom-left (10x10) with blue\n",
        "img[10:, :10] = [255, 0, 0]  # Blue (BGR)\n",
        "\n",
        "# Fill the bottom-right (10x10) with yellow\n",
        "img[10:, 10:] = [0, 255, 255]  # Yellow (BGR)\n",
        "\n",
        "# Display the image\n",
        "cv2_imshow(img)  # For Google Colab\n",
        "# cv2.imshow(\"20x20 Color Icon\", img)  # Use this for local machines\n"
      ],
      "metadata": {
        "id": "UJED3Lk9V9fq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "03e43e7e-480d-421e-d3a9-c30dc06c8e1e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=20x20>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAIAAAAC64paAAAAOElEQVR4AWP8z4APMOKVZsKnlZDcqGZCIYQmP0QDjJGBAV8i+v8fqAAnGKJ+HnU2zhjFLkFRgAEApD0FJBnemGgAAAAASUVORK5CYII=\n",
            "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAUABQDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDi67jw/wD8gS3/AOBf+hGvJP7UvP8Ant/46P8ACvfPhxplnqPgLTLq6h8yeTzdzbiM4lcDgHHQCvJ4t4exWSYKOJxMouLko+623dqT6paaHqcY5jS4jwMMHg04yjNS97RWSkujlr7y6FCiu5/4R/S/+fX/AMiN/jRX55/aFLs/6+Z+b/6n47+eH3v/AORPk2vpT4V/8k20n/tt/wCjnoor918X/wDkR0v+vsf/AEiZ9fl/8V+n+R2NFFFfziewf//Z\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "如上输出,输出了一个小图像."
      ],
      "metadata": {
        "id": "mHTIMDSSpBkZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basic I/O scripts 21\n",
        "Reading/writing an image file 22\n",
        "Converting between an image and raw bytes 24\n",
        "Accessing image data with numpy.array 26\n",
        "Reading/writing a video file 28\n",
        "Capturing camera frames 29\n",
        "Displaying images in a window 31\n",
        "Displaying camera frames in a window 32\n",
        "Project Cameo (face tracking and image manipulation) 34\n",
        "Table of Contents[ ii ]\n",
        "Cameo – an object-oriented design 35\n",
        "Abstracting a video stream with managers.CaptureManager 35\n",
        "Abstracting a window and keyboard with managers.WindowManager 41\n",
        "Applying everything with cameo.Cameo 42\n",
        "Summary 44\n",
        "### Chapter 3: Processing Images with OpenCV 3 45\n",
        "Converting between different color spaces 45\n",
        "A quick note on BGR 46\n",
        "The Fourier Transform 46\n",
        "High pass filter 47\n",
        "Low pass filter 49\n",
        "Creating modules 49\n",
        "Edge detection 49\n",
        "Custom kernels – getting convoluted 51\n",
        "Modifying the application 53\n",
        "Edge detection with Canny 55\n",
        "Contour detection 56\n",
        "Contours – bounding box, minimum area rectangle,\n",
        "and minimum enclosing circle 57\n",
        "Contours – convex contours and the Douglas-Peucker algorithm 60\n",
        "Line and circle detection 62\n",
        "Line detection 62\n",
        "Circle detection 63\n",
        "Detecting shapes 64\n",
        "Summary 65\n",
        "### Chapter 4: Depth Estimation and Segmentation 67\n",
        "Creating modules 67\n",
        "Capturing frames from a depth camera 68\n",
        "Creating a mask from a disparity map 71\n",
        "Masking a copy operation 72\n",
        "Depth estimation with a normal camera 74\n",
        "Object segmentation using the Watershed and GrabCut algorithms 80\n",
        "Example of foreground detection with GrabCut 82\n",
        "Image segmentation with the Watershed algorithm 84\n",
        "Summary 87\n",
        "### Chapter 5: Detecting and Recognizing Faces 89\n",
        "Conceptualizing Haar cascades 90\n",
        "Getting Haar cascade data 91\n",
        "Using OpenCV to perform face detection 91\n",
        "Performing face detection on a still image 92\n",
        "Table of Contents[ iii ]\n",
        "Performing face detection on a video 94\n",
        "Performing face recognition 97\n",
        "Generating the data for face recognition 98\n",
        "Recognizing faces 100\n",
        "Preparing the training data 101\n",
        "Loading the data and recognizing faces 102\n",
        "Performing an Eigenfaces recognition 103\n",
        "Performing face recognition with Fisherfaces 105\n",
        "Performing face recognition with LBPH 106\n",
        "Discarding results with confidence score 106\n",
        "Summary 107\n",
        "### Chapter 6: Retrieving Images and Searching\n",
        "Using Image Descriptors 109\n",
        "Feature detection algorithms 109\n",
        "Defining features 110\n",
        "Detecting features – corners 110\n",
        "Feature extraction and description using DoG and SIFT 113\n",
        "Anatomy of a keypoint 116\n",
        "Feature extraction and detection using Fast Hessian and SURF 117\n",
        "ORB feature detection and feature matching 120\n",
        "FAST 120\n",
        "BRIEF 121\n",
        "Brute-Force matching 121\n",
        "Feature matching with ORB 122\n",
        "Using K-Nearest Neighbors matching 125\n",
        "FLANN-based matching 126\n",
        "FLANN matching with homography 130\n",
        "A sample application – tattoo forensics 133\n",
        "Saving image descriptors to file 133\n",
        "Scanning for matches 134\n",
        "Summary 137\n",
        "### Chapter 7: Detecting and Recognizing Objects 139\n",
        "Object detection and recognition techniques 139\n",
        "HOG descriptors 140\n",
        "The scale issue 142\n",
        "The location issue 142\n",
        "Non-maximum (or non-maxima) suppression 145\n",
        "Support vector machines 146\n",
        "People detection 147\n",
        "Creating and training an object detector 149\n",
        "Bag-of-words 149\n",
        "BOW in computer vision 150\n",
        "Detecting cars 153\n",
        "What did we just do? 155\n",
        "Table of Contents[ iv ]\n",
        "SVM and sliding windows 160\n",
        "Example – car detection in a scene 161\n",
        "Dude, where's my car? 171\n",
        "Summary 175\n",
        "### Chapter 8: Tracking Objects 177\n",
        "Detecting moving objects 177\n",
        "Basic motion detection 178\n",
        "Background subtractors – KNN, MOG2, and GMG 181\n",
        "Meanshift and CAMShift 185\n",
        "Color histograms 188\n",
        "The calcHist function 189\n",
        "The calcBackProject function 190\n",
        "In summary 190\n",
        "Back to the code 191\n",
        "CAMShift 193\n",
        "The Kalman filter 194\n",
        "Predict and update 195\n",
        "An example 196\n",
        "A real-life example – tracking pedestrians 199\n",
        "The application workflow 200\n",
        "A brief digression – functional versus object-oriented programming 200\n",
        "The Pedestrian class 202\n",
        "The main program 205\n",
        "Where do we go from here? 207\n",
        "Summary 208\n",
        "\n",
        "### Chapter 9: Neural Networks with OpenCV – an Introduction 209\n",
        "Artificial neural networks 209\n",
        "Neurons and perceptrons 210\n",
        "The structure of an ANN 211\n",
        "Network layers by example 212\n",
        "The input layer 212\n",
        "The output layer 212\n",
        "The hidden layer 212\n",
        "ANNs in OpenCV 214\n",
        "ANN-imal classification 216\n",
        "Training epochs 220\n",
        "Handwritten digit recognition with ANNs 222\n",
        "MNIST – the handwritten digit database 222\n",
        "Customized training data 222\n",
        "The initial parameters 222\n",
        "The input layer 222\n",
        "The hidden layer 223\n",
        "The output layer 223\n",
        "Table of Contents[ v ]\n",
        "Training epochs 223\n",
        "Other parameters 223\n",
        "Mini-libraries 224\n",
        "The main file 228\n",
        "Possible improvements and potential applications 234\n",
        "Improvements 234\n",
        "Potential applications 235\n",
        "Summary 235\n",
        "To boldly go… 235\n",
        "\n",
        "## progress\n",
        "date | process | time segments | sum\n",
        "-|-|-|-\n",
        "2024-08-19 | created md | 16:30~ |\n",
        "2024-11-26 | 2ch start | 15:00 ~ |\n",
        "\n",
        "~~~py\n",
        "~~~\n",
        "\n",
        "out:\n",
        "~~~sh\n",
        "~~~"
      ],
      "metadata": {
        "id": "egEZ-fA5pkqc"
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}